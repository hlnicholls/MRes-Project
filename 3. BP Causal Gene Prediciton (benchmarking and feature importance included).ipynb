{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Machine Learning for Predicting Blood Pressure Genes__ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy as numpy\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "np.random.seed(7) # for keras reproducibility, set before import as shown in keras examples. https://github.com/keras-team/keras/issues/2743\n",
    "from sklearn import datasets, metrics, preprocessing, model_selection\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelBinarizer,StandardScaler, LabelEncoder, OneHotEncoder \n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold, cross_val_score, cross_val_predict, GridSearchCV\n",
    "from sklearn.metrics import classification_report,confusion_matrix, mean_squared_error, matthews_corrcoef\n",
    "from sklearn.datasets import make_classification, load_digits\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LogisticRegression, LassoCV, LassoLarsCV, LassoLarsIC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "import dask_ml.model_selection as dcv\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "from keras import regularizers\n",
    "from keras.regularizers import l1\n",
    "reg = l1(0.001)\n",
    "\n",
    "\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "from itertools import cycle\n",
    "from scipy import interp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(303, 40)\n"
     ]
    }
   ],
   "source": [
    "dataset= pd.read_csv('BP_training.csv')\n",
    "data = dataset.drop([\"gene\"],1)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing\n",
    "### 1. Impute missing values by mean imputation for individual features\n",
    "### 2. Standardise each feature individually on a scale of 0-1\n",
    " \n",
    "4 categories of affect on BP ranked as numeric values: most likely (1), likely (2), possible  (3), least likely (4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.iloc[:,0:39]\n",
    "imputer = SimpleImputer(missing_values = np.nan, strategy = \"mean\")\n",
    "imputer = imputer.fit(df)\n",
    "df = imputer.transform(df)\n",
    "X = MinMaxScaler().fit_transform(df)\n",
    "\n",
    "Y = data[\"category\"]\n",
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Models:\n",
    "\n",
    "### Hyper-parameter tuning with gridsearchCV, dask parallel processing for efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 7 #enables consistency in entropy for all models\n",
    "\n",
    "\n",
    "#Setting gridsearch parameters for each model\n",
    "\n",
    "logreg = LogisticRegression(penalty='l1', solver='liblinear',multi_class='auto',random_state=seed)\n",
    "LR_par= {'penalty':['l1'], 'C': [0.5, 1, 5, 10], 'max_iter':[500, 1000, 5000]}\n",
    "\n",
    "rfc =RandomForestClassifier(n_estimators=100,random_state=seed)\n",
    "param_grid = {\"max_depth\": [5],\n",
    "             \"max_features\": [\"auto\", \"sqrt\"],\n",
    "              \"min_samples_split\": [50],\n",
    "              \"min_samples_leaf\": [50],\n",
    "              \"bootstrap\": [False, True],\n",
    "              \"criterion\": [\"entropy\",\"gini\"]}\n",
    "\n",
    "gbm = GradientBoostingClassifier(random_state=seed)\n",
    "param = {\"loss\":[\"deviance\"],\n",
    "    \"learning_rate\": [0.001, 0.01],\n",
    "    \"min_samples_split\": [50],\n",
    "    \"min_samples_leaf\": [50],\n",
    "    \"max_depth\":[5],\n",
    "    \"max_features\":[\"auto\"],\n",
    "    \"criterion\": [\"friedman_mse\"],\n",
    "    \"n_estimators\":[1000]\n",
    "    }\n",
    "\n",
    "\n",
    "XGB = XGBClassifier(num_class=4)\n",
    "xgb_parameters = {'nthread':[4], #when use hyperthread, xgboost may become slower\n",
    "              'objective':['multi:softprob'],\n",
    "              'learning_rate': [0.01, 0.001], #so called `eta` value\n",
    "              'max_depth': [5],\n",
    "              'min_child_weight': [11],\n",
    "              'silent': [1],\n",
    "              'subsample': [1.0],\n",
    "              'colsample_bytree': [0.6],\n",
    "              'n_estimators': [1000],\n",
    "              'missing':[-999],\n",
    "              'seed': [7]}\n",
    "                   \n",
    "\n",
    "mlp = MLPClassifier(random_state=seed)\n",
    "parameter_space = {'hidden_layer_sizes': [(50,)],\n",
    "     'activation': ['relu'],\n",
    "     'solver': ['adam'],\n",
    "     'max_iter': [10000],\n",
    "     'alpha': [0.001, 0.01],\n",
    "     'learning_rate': ['constant']}\n",
    "\n",
    "svm = SVC(gamma=\"scale\", probability=True,random_state=seed)\n",
    "tuned_parameters = {'kernel':('linear', 'rbf'), 'C':(0.1, 0.25, 0.5, 0.75, 1.0)}\n",
    "\n",
    "\n",
    "\n",
    "def baseline_model(learn_rate=0.01):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(100, input_dim=X.shape[1], activation='relu', activity_regularizer=l1(0.0001)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(75, activation='relu',activity_regularizer=l1(0.0001))) \n",
    "    model.add(Dense(50, activation='relu',activity_regularizer=l1(0.0001))) \n",
    "    model.add(Dense(25, activation='relu',activity_regularizer=l1(0.0001))) \n",
    "    model.add(Dense(4, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='Nadam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "keras = KerasClassifier(build_fn=baseline_model,batch_size=32, epochs=100, verbose=0)\n",
    "\n",
    "learn_rate = [0.001, 0.01]\n",
    "kerasparams = dict(learn_rate=learn_rate)\n",
    "\n",
    "#creating folds of the training data:\n",
    "\n",
    "inner_cv = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "outer_cv = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "\n",
    "models = []\n",
    "models.append(('LR', dcv.GridSearchCV(logreg, LR_par, cv=inner_cv, iid=False, n_jobs=-1)))\n",
    "models.append(('SVM', dcv.GridSearchCV(svm, tuned_parameters, cv=inner_cv, iid=False, n_jobs=-1)))\n",
    "models.append(('RF', dcv.GridSearchCV(rfc, param_grid, cv=inner_cv,iid=False, n_jobs=-1)))\n",
    "models.append(('GBM', dcv.GridSearchCV(gbm, param, cv=inner_cv,iid=False, n_jobs=-1)))\n",
    "models.append(('XGB',dcv.GridSearchCV(XGB, xgb_parameters,  cv=inner_cv, iid=False, n_jobs=-1)))\n",
    "models.append(('MLP', dcv.GridSearchCV(mlp, parameter_space, cv=inner_cv,iid=False, n_jobs=-1)))\n",
    "models.append(('Keras', GridSearchCV(estimator=keras, param_grid=kerasparams, cv=inner_cv,iid=False, n_jobs=-1)))\n",
    "\n",
    "results = []\n",
    "names = []\n",
    "scoring = 'accuracy'\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation:\n",
    "### Nested k-fold cross-validation (k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nested CV Accuracy LR: 67.021858 (+/- 6.719667 )\n",
      "Test set accuracy: 72.13 %\n",
      "Best Parameters: \n",
      "{'C': 0.5, 'max_iter': 500, 'penalty': 'l1'}\n",
      "\n",
      "Nested CV Accuracy SVM: 65.699454 (+/- 6.643326 )\n",
      "Test set accuracy: 67.21 %\n",
      "Best Parameters: \n",
      "{'C': 1.0, 'kernel': 'rbf'}\n",
      "\n",
      "Nested CV Accuracy RF: 65.071038 (+/- 8.548003 )\n",
      "Test set accuracy: 67.21 %\n",
      "Best Parameters: \n",
      "{'bootstrap': False, 'criterion': 'gini', 'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 50, 'min_samples_split': 50}\n",
      "\n",
      "Nested CV Accuracy GBM: 71.644809 (+/- 4.440186 )\n",
      "Test set accuracy: 67.21 %\n",
      "Best Parameters: \n",
      "{'criterion': 'friedman_mse', 'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 50, 'min_samples_split': 50, 'n_estimators': 1000}\n",
      "\n",
      "Nested CV Accuracy XGB: 71.650273 (+/- 5.977817 )\n",
      "Test set accuracy: 72.13 %\n",
      "Best Parameters: \n",
      "{'colsample_bytree': 0.6, 'learning_rate': 0.001, 'max_depth': 5, 'min_child_weight': 11, 'missing': -999, 'n_estimators': 1000, 'nthread': 4, 'objective': 'multi:softprob', 'seed': 7, 'silent': 1, 'subsample': 1.0}\n",
      "\n",
      "Nested CV Accuracy MLP: 64.366120 (+/- 5.858382 )\n",
      "Test set accuracy: 54.10 %\n",
      "Best Parameters: \n",
      "{'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (50,), 'learning_rate': 'constant', 'max_iter': 10000, 'solver': 'adam'}\n",
      "\n",
      "Nested CV Accuracy Keras: 66.360656 (+/- 5.520327 )\n",
      "Test set accuracy: 59.02 %\n",
      "Best Parameters: \n",
      "{'learn_rate': 0.01}\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.57377049, 0.72131148, 0.63934426, 0.76666667, 0.65      ]), array([0.6557377 , 0.60655738, 0.63934426, 0.78333333, 0.6       ]), array([0.52459016, 0.60655738, 0.6557377 , 0.78333333, 0.68333333]), array([0.67213115, 0.70491803, 0.68852459, 0.8       , 0.71666667]), array([0.6557377 , 0.73770492, 0.6557377 , 0.81666667, 0.71666667]), array([0.59016393, 0.73770492, 0.57377049, 0.66666667, 0.65      ]), array([0.57377049, 0.70491803, 0.63934426, 0.73333333, 0.66666667])]\n"
     ]
    }
   ],
   "source": [
    "for name, model in models:\n",
    "    nested_cv_results = model_selection.cross_val_score(model, X, Y, cv=outer_cv, scoring=scoring)\n",
    "    results.append(nested_cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"Nested CV Accuracy %s: %f (+/- %f )\" % (name, nested_cv_results.mean()*100, nested_cv_results.std()*100)\n",
    "    print(msg)\n",
    "    model.fit(X_train, Y_train)\n",
    "    print('Test set accuracy: {:.2f}'.format(model.score(X_test, Y_test)*100),  '%')\n",
    "    print(\"Best Parameters: \\n{}\\n\".format(model.best_params_))\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Nested Cross-Validation Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR report: \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      " 1 Most likely       0.00      0.00      0.00         4\n",
      "      2 Likely       0.59      0.84      0.70        19\n",
      "    3 Possible       0.50      0.31      0.38        13\n",
      "4 Least likely       0.92      0.96      0.94        25\n",
      "\n",
      "      accuracy                           0.72        61\n",
      "     macro avg       0.50      0.53      0.50        61\n",
      "  weighted avg       0.67      0.72      0.68        61\n",
      "\n",
      "LR MCC: 0.5913104673680332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM report: \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      " 1 Most likely       0.00      0.00      0.00         4\n",
      "      2 Likely       0.58      0.74      0.65        19\n",
      "    3 Possible       0.31      0.31      0.31        13\n",
      "4 Least likely       0.96      0.92      0.94        25\n",
      "\n",
      "      accuracy                           0.67        61\n",
      "     macro avg       0.46      0.49      0.47        61\n",
      "  weighted avg       0.64      0.67      0.65        61\n",
      "\n",
      "SVM MCC: 0.5157924292439348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF report: \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      " 1 Most likely       0.00      0.00      0.00         4\n",
      "      2 Likely       0.51      0.95      0.67        19\n",
      "    3 Possible       0.00      0.00      0.00        13\n",
      "4 Least likely       0.88      0.92      0.90        25\n",
      "\n",
      "      accuracy                           0.67        61\n",
      "     macro avg       0.35      0.47      0.39        61\n",
      "  weighted avg       0.52      0.67      0.58        61\n",
      "\n",
      "RF MCC: 0.5505273568223312\n",
      "GBM report: \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      " 1 Most likely       0.00      0.00      0.00         4\n",
      "      2 Likely       0.59      0.68      0.63        19\n",
      "    3 Possible       0.36      0.38      0.37        13\n",
      "4 Least likely       0.96      0.92      0.94        25\n",
      "\n",
      "      accuracy                           0.67        61\n",
      "     macro avg       0.48      0.50      0.49        61\n",
      "  weighted avg       0.65      0.67      0.66        61\n",
      "\n",
      "GBM MCC: 0.5174275326956864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB report: \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      " 1 Most likely       0.00      0.00      0.00         4\n",
      "      2 Likely       0.67      0.74      0.70        19\n",
      "    3 Possible       0.46      0.46      0.46        13\n",
      "4 Least likely       0.89      0.96      0.92        25\n",
      "\n",
      "      accuracy                           0.72        61\n",
      "     macro avg       0.50      0.54      0.52        61\n",
      "  weighted avg       0.67      0.72      0.69        61\n",
      "\n",
      "XGB MCC: 0.5846864267950294\n",
      "MLP report: \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      " 1 Most likely       0.00      0.00      0.00         4\n",
      "      2 Likely       0.47      0.47      0.47        19\n",
      "    3 Possible       0.16      0.23      0.19        13\n",
      "4 Least likely       0.95      0.84      0.89        25\n",
      "\n",
      "      accuracy                           0.54        61\n",
      "     macro avg       0.40      0.39      0.39        61\n",
      "  weighted avg       0.57      0.54      0.55        61\n",
      "\n",
      "MLP MCC: 0.3361064394597724\n",
      "Keras report: \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      " 1 Most likely       0.00      0.00      0.00         4\n",
      "      2 Likely       0.50      0.53      0.51        19\n",
      "    3 Possible       0.19      0.23      0.21        13\n",
      "4 Least likely       0.96      0.96      0.96        25\n",
      "\n",
      "      accuracy                           0.61        61\n",
      "     macro avg       0.41      0.43      0.42        61\n",
      "  weighted avg       0.59      0.61      0.60        61\n",
      "\n",
      "Keras MCC: 0.418538578804782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "for name, model in models:\n",
    "    model.fit(X_train, Y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    target_names=['1 Most likely', '2 Likely', '3 Possible', '4 Least likely']\n",
    "    print(name, 'report:','\\n', classification_report(Y_test, y_pred, target_names=target_names))\n",
    "    print(name, 'MCC:', matthews_corrcoef(Y_test, y_pred)) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importance\n",
    "\n",
    "- Without gridsearch due to it not working with coef and importance scikit functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All LR feature weights:\n",
      "[[ 0.55564202  0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.28473091  0.7505027\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.21081768  0.         -0.85543426  0.          0.          0.\n",
      "   0.          0.          0.        ]\n",
      " [-0.12777912  0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.         -0.84557476  0.         -0.02133886\n",
      "   0.          0.         -0.88845367  0.         -0.19453533  0.\n",
      "   0.60038659  0.          0.          1.0020457   0.         -0.37944532\n",
      "   0.          0.11929986  1.290072    0.          0.41248349  0.\n",
      "   1.13220211  0.94442542  0.31489932]\n",
      " [ 0.44414558  0.          0.          0.          0.          0.\n",
      "   0.          0.         -1.16377647  0.          0.          0.\n",
      "   0.          0.         -0.17932582  0.23451355  0.          0.\n",
      "   0.          0.60835281  1.25732744  0.03369413  0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.73397774  0.          0.          0.45420519  0.          0.\n",
      "   0.          0.          0.26637127]\n",
      " [-0.57799082  0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "  -0.41010251  0.          0.          0.          0.          0.\n",
      "  -0.54922914  0.          0.          0.          0.          0.\n",
      "  -2.08884474 -1.12377977 -1.28668318 -0.61805107  0.         -0.63205577\n",
      "  -2.43585749 -0.32590422 -2.95820443]]\n",
      "Most likely coefficients:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Catalog</td>\n",
       "      <td>0.555642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CLNDN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>InterVarautomated</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Polyphen2_HVAR_pred</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>REVEL</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SIFTpred</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GERPrankscore</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>eigenraw</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>eigenpcraw</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CADDrankscore</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DANNrankscore</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>fathmmrankscore</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>fathmmpred</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>minP</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>deepseasignifscore</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Exomiser.score</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>wgencode</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>regulomedscore</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>qvalAT</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>qvalLV</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>qvalAD</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>qvalAO</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>qvalTIB</td>\n",
       "      <td>0.284731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>qvalBL</td>\n",
       "      <td>0.750503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>qvalCO</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>qvaladiSub</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>qvaladiVsc</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>qvallung</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>qvalthyroid</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>qvalSkeletal</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>qvalpituit</td>\n",
       "      <td>0.210818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>qvalspleen</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>qvalleg</td>\n",
       "      <td>-0.855434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>qvalEsoph</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>qvalstomach</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>qvalileum</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>qvalpancr</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>qvalSaliv</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>qvalhippo</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0         0\n",
       "0               Catalog  0.555642\n",
       "1                 CLNDN  0.000000\n",
       "2     InterVarautomated  0.000000\n",
       "3   Polyphen2_HVAR_pred  0.000000\n",
       "4                 REVEL  0.000000\n",
       "5              SIFTpred  0.000000\n",
       "6         GERPrankscore  0.000000\n",
       "7              eigenraw  0.000000\n",
       "8            eigenpcraw  0.000000\n",
       "9         CADDrankscore  0.000000\n",
       "10        DANNrankscore  0.000000\n",
       "11      fathmmrankscore  0.000000\n",
       "12           fathmmpred  0.000000\n",
       "13                 minP  0.000000\n",
       "14   deepseasignifscore  0.000000\n",
       "15       Exomiser.score  0.000000\n",
       "16             wgencode  0.000000\n",
       "17       regulomedscore  0.000000\n",
       "18               qvalAT  0.000000\n",
       "19               qvalLV  0.000000\n",
       "20               qvalAD  0.000000\n",
       "21               qvalAO  0.000000\n",
       "22              qvalTIB  0.284731\n",
       "23               qvalBL  0.750503\n",
       "24               qvalCO  0.000000\n",
       "25           qvaladiSub  0.000000\n",
       "26           qvaladiVsc  0.000000\n",
       "27             qvallung  0.000000\n",
       "28          qvalthyroid  0.000000\n",
       "29         qvalSkeletal  0.000000\n",
       "30           qvalpituit  0.210818\n",
       "31           qvalspleen  0.000000\n",
       "32              qvalleg -0.855434\n",
       "33            qvalEsoph  0.000000\n",
       "34          qvalstomach  0.000000\n",
       "35            qvalileum  0.000000\n",
       "36            qvalpancr  0.000000\n",
       "37            qvalSaliv  0.000000\n",
       "38            qvalhippo  0.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression(penalty='l1', C=0.5, max_iter=500, solver='liblinear',multi_class='auto') \n",
    "logreg.fit(X_train, Y_train)\n",
    "print('All LR feature weights:')\n",
    "coef_mostlikely=logreg.coef_[0]\n",
    "coef_likely=logreg.coef_[1]\n",
    "coef_possible_=logreg.coef_[2]\n",
    "coef_leastlikely=logreg.coef_[3]\n",
    "coef=logreg.coef_\n",
    "intercept=logreg.intercept_\n",
    "classes=logreg.classes_\n",
    "print(coef)\n",
    "\n",
    "\n",
    "\n",
    "model_features =['Catalog','CLNDN', 'InterVarautomated', 'Polyphen2_HVAR_pred','REVEL', 'SIFTpred', 'GERPrankscore', 'eigenraw', 'eigenpcraw',\n",
    "                 'CADDrankscore','DANNrankscore','fathmmrankscore','fathmmpred','minP','deepseasignifscore','Exomiser.score','wgencode','regulomedscore',\n",
    "                 'qvalAT','qvalLV','qvalAD', 'qvalAO','qvalTIB','qvalBL','qvalCO','qvaladiSub','qvaladiVsc','qvallung','qvalthyroid','qvalSkeletal',\n",
    "                 'qvalpituit','qvalspleen', 'qvalleg', 'qvalEsoph', 'qvalstomach', 'qvalileum', 'qvalpancr', 'qvalSaliv', 'qvalhippo']\n",
    "\n",
    "feature = pd.DataFrame(np.array(model_features))\n",
    "\n",
    "output1 = list(coef_mostlikely)\n",
    "\n",
    "df = pd.DataFrame(np.array(output1))\n",
    "\n",
    "df_total = pd.concat([feature, df], axis=1)\n",
    "print(\"Most likely coefficients:\")\n",
    "df_total.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFC Feature ranking:\n",
      "1. feature 36 (0.186342)\n",
      "2. feature 38 (0.174243)\n",
      "3. feature 34 (0.167475)\n",
      "4. feature 32 (0.111695)\n",
      "5. feature 26 (0.092615)\n",
      "6. feature 33 (0.092156)\n",
      "7. feature 30 (0.088425)\n",
      "8. feature 14 (0.017001)\n",
      "9. feature 27 (0.012405)\n",
      "10. feature 28 (0.011994)\n",
      "11. feature 15 (0.011828)\n",
      "12. feature 22 (0.010982)\n",
      "13. feature 37 (0.006936)\n",
      "14. feature 29 (0.006354)\n",
      "15. feature 20 (0.005459)\n",
      "16. feature 16 (0.001806)\n",
      "17. feature 23 (0.001757)\n",
      "18. feature 35 (0.000527)\n",
      "19. feature 6 (0.000000)\n",
      "20. feature 8 (0.000000)\n",
      "21. feature 7 (0.000000)\n",
      "22. feature 3 (0.000000)\n",
      "23. feature 5 (0.000000)\n",
      "24. feature 4 (0.000000)\n",
      "25. feature 10 (0.000000)\n",
      "26. feature 2 (0.000000)\n",
      "27. feature 1 (0.000000)\n",
      "28. feature 9 (0.000000)\n",
      "29. feature 19 (0.000000)\n",
      "30. feature 11 (0.000000)\n",
      "31. feature 12 (0.000000)\n",
      "32. feature 13 (0.000000)\n",
      "33. feature 17 (0.000000)\n",
      "34. feature 18 (0.000000)\n",
      "35. feature 21 (0.000000)\n",
      "36. feature 24 (0.000000)\n",
      "37. feature 25 (0.000000)\n",
      "38. feature 31 (0.000000)\n",
      "39. feature 0 (0.000000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "rfc =RandomForestClassifier(bootstrap=False, criterion='gini', max_depth=10, max_features='auto', min_samples_leaf=50, min_samples_split=50)\n",
    "rfc.fit(X_train,Y_train)\n",
    "\n",
    "importances = rfc.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in rfc.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"RFC Feature ranking:\")\n",
    "\n",
    "for f in range(X_train.shape[1]):\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0 17 13 12 11 10  8  9  6  5  4  3  2  1  7 21 26 33 24 16 29 23 28 18\n",
      " 35 25 22 31 14 37 19 27 15 32 34 30 36 20 38]\n",
      " GBM Feature ranking:\n",
      "1. feature 38 (0.162630)\n",
      "2. feature 20 (0.143572)\n",
      "3. feature 36 (0.102540)\n",
      "4. feature 30 (0.102159)\n",
      "5. feature 34 (0.099151)\n",
      "6. feature 32 (0.076635)\n",
      "7. feature 15 (0.058044)\n",
      "8. feature 27 (0.044745)\n",
      "9. feature 19 (0.042648)\n",
      "10. feature 37 (0.034958)\n",
      "11. feature 14 (0.017364)\n",
      "12. feature 31 (0.016550)\n",
      "13. feature 22 (0.015421)\n",
      "14. feature 25 (0.013181)\n",
      "15. feature 35 (0.012849)\n",
      "16. feature 18 (0.010020)\n",
      "17. feature 28 (0.010007)\n",
      "18. feature 23 (0.008457)\n",
      "19. feature 29 (0.008049)\n",
      "20. feature 16 (0.006942)\n",
      "21. feature 24 (0.006855)\n",
      "22. feature 33 (0.004811)\n",
      "23. feature 26 (0.001302)\n",
      "24. feature 21 (0.001108)\n",
      "25. feature 7 (0.000000)\n",
      "26. feature 1 (0.000000)\n",
      "27. feature 2 (0.000000)\n",
      "28. feature 3 (0.000000)\n",
      "29. feature 4 (0.000000)\n",
      "30. feature 5 (0.000000)\n",
      "31. feature 6 (0.000000)\n",
      "32. feature 9 (0.000000)\n",
      "33. feature 8 (0.000000)\n",
      "34. feature 10 (0.000000)\n",
      "35. feature 11 (0.000000)\n",
      "36. feature 12 (0.000000)\n",
      "37. feature 13 (0.000000)\n",
      "38. feature 17 (0.000000)\n",
      "39. feature 0 (0.000000)\n"
     ]
    }
   ],
   "source": [
    "gbm = GradientBoostingClassifier(criterion='friedman_mse', learning_rate=0.01, loss='deviance', max_depth=10, max_features='auto', min_samples_leaf=50, min_samples_split=50, n_estimators=500)\n",
    "\n",
    "gbm.fit(X_train,Y_train)\n",
    "\n",
    "feature_importance = gbm.feature_importances_\n",
    "# make importances relative to max importance\n",
    "feature_importance = 100.0 * (feature_importance / feature_importance.max())\n",
    "sorted_idx = np.argsort(feature_importance)\n",
    "pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "\n",
    "print(np.argsort(feature_importance))\n",
    "\n",
    "importances = gbm.feature_importances_\n",
    "\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\" GBM Feature ranking:\")\n",
    "\n",
    "for f in range(X_train.shape[1]):\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 9  1  2  3  4  5  6  7  8 17 10 11 12 23 16 14 21 24 13  0 35 26 29 28\n",
      " 33 37 22 19 18 15 31 32 27 20 38 30 36 25 34]\n",
      "XGB Feature ranking:\n",
      "1. feature 34 (0.198263)\n",
      "2. feature 25 (0.129527)\n",
      "3. feature 36 (0.095241)\n",
      "4. feature 30 (0.064993)\n",
      "5. feature 38 (0.056683)\n",
      "6. feature 20 (0.055852)\n",
      "7. feature 27 (0.054265)\n",
      "8. feature 32 (0.043217)\n",
      "9. feature 31 (0.033644)\n",
      "10. feature 15 (0.030014)\n",
      "11. feature 18 (0.026235)\n",
      "12. feature 19 (0.023550)\n",
      "13. feature 22 (0.021667)\n",
      "14. feature 37 (0.020541)\n",
      "15. feature 33 (0.019170)\n",
      "16. feature 28 (0.018504)\n",
      "17. feature 29 (0.017354)\n",
      "18. feature 26 (0.015698)\n",
      "19. feature 35 (0.013432)\n",
      "20. feature 0 (0.011945)\n",
      "21. feature 13 (0.010915)\n",
      "22. feature 24 (0.010598)\n",
      "23. feature 21 (0.010157)\n",
      "24. feature 14 (0.009828)\n",
      "25. feature 16 (0.004905)\n",
      "26. feature 23 (0.003802)\n",
      "27. feature 12 (0.000000)\n",
      "28. feature 11 (0.000000)\n",
      "29. feature 10 (0.000000)\n",
      "30. feature 17 (0.000000)\n",
      "31. feature 8 (0.000000)\n",
      "32. feature 7 (0.000000)\n",
      "33. feature 6 (0.000000)\n",
      "34. feature 5 (0.000000)\n",
      "35. feature 4 (0.000000)\n",
      "36. feature 3 (0.000000)\n",
      "37. feature 2 (0.000000)\n",
      "38. feature 1 (0.000000)\n",
      "39. feature 9 (0.000000)\n"
     ]
    }
   ],
   "source": [
    "XGB = XGBClassifier(colsample_bytree=0.6, learning_rate=0.001, max_depth=5, min_child_weight=11, missing=-999, n_estimators=1000, nthread=4, objective='multi:softprob', seed=7, silent=1, subsample=1.0)\n",
    "\n",
    "XGB.fit(X_train,Y_train)\n",
    "\n",
    "feature_importance = XGB.feature_importances_\n",
    "# make importances relative to max importance\n",
    "feature_importance = 100.0 * (feature_importance / feature_importance.max())\n",
    "sorted_idx = np.argsort(feature_importance)\n",
    "pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "\n",
    "print(np.argsort(feature_importance))\n",
    "\n",
    "importances = XGB.feature_importances_\n",
    "\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"XGB Feature ranking:\")\n",
    "\n",
    "for f in range(X_train.shape[1]):\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
       "    <thead>\n",
       "    <tr style=\"border: none;\">\n",
       "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
       "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "    </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.1413\n",
       "                \n",
       "                    &plusmn; 0.0298\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x32\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 84.39%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0992\n",
       "                \n",
       "                    &plusmn; 0.0209\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x20\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 93.02%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0314\n",
       "                \n",
       "                    &plusmn; 0.0193\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x27\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 93.54%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0281\n",
       "                \n",
       "                    &plusmn; 0.0142\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x36\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 93.81%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0264\n",
       "                \n",
       "                    &plusmn; 0.0040\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x0\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 94.65%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0215\n",
       "                \n",
       "                    &plusmn; 0.0110\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x16\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 94.65%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0215\n",
       "                \n",
       "                    &plusmn; 0.0142\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x33\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 95.24%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0182\n",
       "                \n",
       "                    &plusmn; 0.0040\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x21\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 95.39%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0174\n",
       "                \n",
       "                    &plusmn; 0.0096\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x30\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 95.55%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0165\n",
       "                \n",
       "                    &plusmn; 0.0196\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x31\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 95.70%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0157\n",
       "                \n",
       "                    &plusmn; 0.0121\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x19\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 95.86%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0149\n",
       "                \n",
       "                    &plusmn; 0.0099\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x22\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.19%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0132\n",
       "                \n",
       "                    &plusmn; 0.0096\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x17\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.19%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0132\n",
       "                \n",
       "                    &plusmn; 0.0121\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x23\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.19%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0132\n",
       "                \n",
       "                    &plusmn; 0.0121\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x24\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.36%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0124\n",
       "                \n",
       "                    &plusmn; 0.0052\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x15\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.36%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0124\n",
       "                \n",
       "                    &plusmn; 0.0117\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x38\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.53%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0116\n",
       "                \n",
       "                    &plusmn; 0.0062\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x37\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.53%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0116\n",
       "                \n",
       "                    &plusmn; 0.0033\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x26\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.53%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0116\n",
       "                \n",
       "                    &plusmn; 0.0081\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x18\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "    \n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 96.53%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 19 more &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "    \n",
       "    </tbody>\n",
       "</table>\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model = KerasClassifier(build_fn=baseline_model, epochs=150, batch_size=32, verbose=0)\n",
    "my_model.fit(X_train, Y_train) \n",
    "\n",
    "perm = PermutationImportance(my_model, random_state=1).fit(X_train, Y_train)\n",
    "df = pd.DataFrame(X_train)\n",
    "eli5.show_weights(perm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
       "    <thead>\n",
       "    <tr style=\"border: none;\">\n",
       "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
       "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "    </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0421\n",
       "                \n",
       "                    &plusmn; 0.0160\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x20\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 82.25%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0355\n",
       "                \n",
       "                    &plusmn; 0.0170\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x27\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 86.86%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0231\n",
       "                \n",
       "                    &plusmn; 0.0112\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x30\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 87.19%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0223\n",
       "                \n",
       "                    &plusmn; 0.0206\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x19\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 89.25%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0174\n",
       "                \n",
       "                    &plusmn; 0.0184\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x38\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 90.35%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0149\n",
       "                \n",
       "                    &plusmn; 0.0153\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x21\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 90.35%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0149\n",
       "                \n",
       "                    &plusmn; 0.0066\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x16\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 90.73%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0140\n",
       "                \n",
       "                    &plusmn; 0.0243\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x36\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 91.12%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0132\n",
       "                \n",
       "                    &plusmn; 0.0062\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x15\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 91.91%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0116\n",
       "                \n",
       "                    &plusmn; 0.0205\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x33\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 92.32%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0107\n",
       "                \n",
       "                    &plusmn; 0.0066\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x24\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 93.17%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0091\n",
       "                \n",
       "                    &plusmn; 0.0132\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x34\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 93.17%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0091\n",
       "                \n",
       "                    &plusmn; 0.0033\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x18\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 93.17%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0091\n",
       "                \n",
       "                    &plusmn; 0.0062\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x0\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 93.61%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0083\n",
       "                \n",
       "                    &plusmn; 0.0209\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x37\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 94.06%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0074\n",
       "                \n",
       "                    &plusmn; 0.0062\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x17\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 95.02%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0058\n",
       "                \n",
       "                    &plusmn; 0.0040\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x6\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 95.02%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0058\n",
       "                \n",
       "                    &plusmn; 0.0040\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x35\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 95.53%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0050\n",
       "                \n",
       "                    &plusmn; 0.0132\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x31\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.06%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0041\n",
       "                \n",
       "                    &plusmn; 0.0117\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x28\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "    \n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 96.06%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 19 more &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "    \n",
       "    </tbody>\n",
       "</table>\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = SVC(gamma=\"scale\", probability=True,random_state=seed, C=0.75, kernel='rbf')\n",
    "\n",
    "svm.fit(X_train, Y_train) \n",
    "\n",
    "perm = PermutationImportance(svm, random_state=1).fit(X_train, Y_train)\n",
    "df = pd.DataFrame(X_train)\n",
    "eli5.show_weights(perm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
       "    <thead>\n",
       "    <tr style=\"border: none;\">\n",
       "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
       "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "    </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.1653\n",
       "                \n",
       "                    &plusmn; 0.0188\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x32\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 85.45%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.1050\n",
       "                \n",
       "                    &plusmn; 0.0457\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x20\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 85.69%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.1025\n",
       "                \n",
       "                    &plusmn; 0.0169\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x27\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 89.56%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0653\n",
       "                \n",
       "                    &plusmn; 0.0218\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x36\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 90.31%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0587\n",
       "                \n",
       "                    &plusmn; 0.0121\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x38\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 90.41%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0579\n",
       "                \n",
       "                    &plusmn; 0.0117\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x0\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 91.19%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0512\n",
       "                \n",
       "                    &plusmn; 0.0178\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x30\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 91.39%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0496\n",
       "                \n",
       "                    &plusmn; 0.0148\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x22\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 93.40%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0339\n",
       "                \n",
       "                    &plusmn; 0.0081\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x33\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 93.52%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0331\n",
       "                \n",
       "                    &plusmn; 0.0173\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x19\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 93.98%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0298\n",
       "                \n",
       "                    &plusmn; 0.0191\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x29\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 94.33%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0273\n",
       "                \n",
       "                    &plusmn; 0.0134\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x16\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 95.20%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0215\n",
       "                \n",
       "                    &plusmn; 0.0062\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x15\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 95.47%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0198\n",
       "                \n",
       "                    &plusmn; 0.0169\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x37\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.29%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0149\n",
       "                \n",
       "                    &plusmn; 0.0066\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x26\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.29%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0149\n",
       "                \n",
       "                    &plusmn; 0.0040\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x21\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.44%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0140\n",
       "                \n",
       "                    &plusmn; 0.0112\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x31\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.44%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0140\n",
       "                \n",
       "                    &plusmn; 0.0084\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x23\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.59%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0132\n",
       "                \n",
       "                    &plusmn; 0.0121\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x25\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.59%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0132\n",
       "                \n",
       "                    &plusmn; 0.0081\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x11\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "    \n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 96.59%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 19 more &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "    \n",
       "    </tbody>\n",
       "</table>\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPClassifier(random_state=seed, activation='relu', alpha=0.001, hidden_layer_sizes=(50,), learning_rate='constant', max_iter=10000, solver='adam')\n",
    "mlp.fit(X_train, Y_train)\n",
    "mlpcoef=mlp.coefs_[0]\n",
    "\n",
    "perm = PermutationImportance(mlp, random_state=1).fit(X_train, Y_train)\n",
    "df = pd.DataFrame(X_train)\n",
    "eli5.show_weights(perm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unknown gene prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1990, 40)\n"
     ]
    }
   ],
   "source": [
    "dataset_unknown= pd.read_csv('BP_unknown.csv')\n",
    "dataunknown = dataset_unknown.drop([\"gene\"],1)\n",
    "print(dataunknown.shape)\n",
    "\n",
    "df =dataunknown.iloc[:,0:39]\n",
    "imputer = SimpleImputer(missing_values = np.nan, strategy = \"mean\")\n",
    "imputer = imputer.fit(df)\n",
    "df = imputer.transform(df)\n",
    "#print(df)\n",
    "X2 = MinMaxScaler().fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene</th>\n",
       "      <th>Catalog</th>\n",
       "      <th>CLNDN</th>\n",
       "      <th>InterVarautomated</th>\n",
       "      <th>Polyphen2_HVAR_pred</th>\n",
       "      <th>REVEL</th>\n",
       "      <th>SIFTpred</th>\n",
       "      <th>GERPrankscore</th>\n",
       "      <th>eigenraw</th>\n",
       "      <th>eigenpcraw</th>\n",
       "      <th>...</th>\n",
       "      <th>qvalileum</th>\n",
       "      <th>qvalpancr</th>\n",
       "      <th>qvalSaliv</th>\n",
       "      <th>qvalhippo</th>\n",
       "      <th>category</th>\n",
       "      <th>XGB prediction</th>\n",
       "      <th>Mostlikely</th>\n",
       "      <th>Likely</th>\n",
       "      <th>Possible</th>\n",
       "      <th>Leastlikely</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAMDC</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.148238</td>\n",
       "      <td>0.274318</td>\n",
       "      <td>0.527257</td>\n",
       "      <td>0.278350</td>\n",
       "      <td>unknown</td>\n",
       "      <td>3</td>\n",
       "      <td>0.065207</td>\n",
       "      <td>0.342341</td>\n",
       "      <td>0.561349</td>\n",
       "      <td>0.031103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABCB9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.006901</td>\n",
       "      <td>0.540455</td>\n",
       "      <td>0.124332</td>\n",
       "      <td>unknown</td>\n",
       "      <td>3</td>\n",
       "      <td>0.064875</td>\n",
       "      <td>0.110591</td>\n",
       "      <td>0.643708</td>\n",
       "      <td>0.180826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABCC8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.156097</td>\n",
       "      <td>0.234632</td>\n",
       "      <td>0.379621</td>\n",
       "      <td>0.000418</td>\n",
       "      <td>unknown</td>\n",
       "      <td>4</td>\n",
       "      <td>0.235413</td>\n",
       "      <td>0.232970</td>\n",
       "      <td>0.118244</td>\n",
       "      <td>0.413373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABCC9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.145449</td>\n",
       "      <td>0.003470</td>\n",
       "      <td>0.277516</td>\n",
       "      <td>0.153735</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1</td>\n",
       "      <td>0.408808</td>\n",
       "      <td>0.213396</td>\n",
       "      <td>0.338913</td>\n",
       "      <td>0.038883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABHD16A</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.262023</td>\n",
       "      <td>0.016786</td>\n",
       "      <td>0.500810</td>\n",
       "      <td>0.333032</td>\n",
       "      <td>unknown</td>\n",
       "      <td>2</td>\n",
       "      <td>0.134594</td>\n",
       "      <td>0.586319</td>\n",
       "      <td>0.185701</td>\n",
       "      <td>0.093387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ABHD17C</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.161608</td>\n",
       "      <td>0.103821</td>\n",
       "      <td>0.061630</td>\n",
       "      <td>0.235442</td>\n",
       "      <td>unknown</td>\n",
       "      <td>3</td>\n",
       "      <td>0.073422</td>\n",
       "      <td>0.212372</td>\n",
       "      <td>0.678232</td>\n",
       "      <td>0.035974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ABI3BP</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.332400</td>\n",
       "      <td>0.222817</td>\n",
       "      <td>0.204093</td>\n",
       "      <td>0.131464</td>\n",
       "      <td>unknown</td>\n",
       "      <td>3</td>\n",
       "      <td>0.009654</td>\n",
       "      <td>0.132205</td>\n",
       "      <td>0.847801</td>\n",
       "      <td>0.010340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AC002117.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.329621</td>\n",
       "      <td>0.306266</td>\n",
       "      <td>0.527257</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>2</td>\n",
       "      <td>0.023363</td>\n",
       "      <td>0.643415</td>\n",
       "      <td>0.327325</td>\n",
       "      <td>0.005896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AC003973.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>2</td>\n",
       "      <td>0.030693</td>\n",
       "      <td>0.577755</td>\n",
       "      <td>0.378561</td>\n",
       "      <td>0.012992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AC003973.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>2</td>\n",
       "      <td>0.031025</td>\n",
       "      <td>0.579909</td>\n",
       "      <td>0.375673</td>\n",
       "      <td>0.013392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AC004156.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200405</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.193655</td>\n",
       "      <td>unknown</td>\n",
       "      <td>2</td>\n",
       "      <td>0.010058</td>\n",
       "      <td>0.743562</td>\n",
       "      <td>0.240836</td>\n",
       "      <td>0.005544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AC004920.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>2</td>\n",
       "      <td>0.028106</td>\n",
       "      <td>0.640932</td>\n",
       "      <td>0.318763</td>\n",
       "      <td>0.012198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>AC004920.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>2</td>\n",
       "      <td>0.033931</td>\n",
       "      <td>0.563124</td>\n",
       "      <td>0.389203</td>\n",
       "      <td>0.013742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>AC005027.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>2</td>\n",
       "      <td>0.031055</td>\n",
       "      <td>0.583606</td>\n",
       "      <td>0.372097</td>\n",
       "      <td>0.013242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>AC005592.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.405341</td>\n",
       "      <td>0.216265</td>\n",
       "      <td>unknown</td>\n",
       "      <td>2</td>\n",
       "      <td>0.026258</td>\n",
       "      <td>0.624224</td>\n",
       "      <td>0.336943</td>\n",
       "      <td>0.012575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>AC005609.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>2</td>\n",
       "      <td>0.024364</td>\n",
       "      <td>0.678959</td>\n",
       "      <td>0.286056</td>\n",
       "      <td>0.010621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>AC006369.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003511</td>\n",
       "      <td>0.060660</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>2</td>\n",
       "      <td>0.028955</td>\n",
       "      <td>0.510894</td>\n",
       "      <td>0.399275</td>\n",
       "      <td>0.060876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>AC007381.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>2</td>\n",
       "      <td>0.032494</td>\n",
       "      <td>0.660497</td>\n",
       "      <td>0.295772</td>\n",
       "      <td>0.011237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>AC007563.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>2</td>\n",
       "      <td>0.037280</td>\n",
       "      <td>0.494404</td>\n",
       "      <td>0.456722</td>\n",
       "      <td>0.011594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>AC007796.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.363798</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.235333</td>\n",
       "      <td>unknown</td>\n",
       "      <td>2</td>\n",
       "      <td>0.041377</td>\n",
       "      <td>0.563376</td>\n",
       "      <td>0.378437</td>\n",
       "      <td>0.016810</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          gene  Catalog  CLNDN  InterVarautomated  Polyphen2_HVAR_pred  REVEL  \\\n",
       "0        AAMDC        0    0.0                0.0                  0.0  0.000   \n",
       "1        ABCB9        0    0.0                0.0                  0.0  0.000   \n",
       "2        ABCC8        0    0.0                0.0                  0.0  0.000   \n",
       "3        ABCC9        0    0.0                0.0                  0.0  0.000   \n",
       "4      ABHD16A        0    0.0                0.0                  0.0  0.000   \n",
       "5      ABHD17C        3    0.0                0.0                  0.0  0.000   \n",
       "6       ABI3BP        0    0.0                0.0                  0.0  0.053   \n",
       "7   AC002117.1        0    0.0                0.0                  0.0  0.000   \n",
       "8   AC003973.4        0    0.0                0.0                  0.0  0.000   \n",
       "9   AC003973.5        0    0.0                0.0                  0.0  0.000   \n",
       "10  AC004156.3        0    0.0                0.0                  0.0  0.000   \n",
       "11  AC004920.2        0    0.0                0.0                  0.0  0.000   \n",
       "12  AC004920.3        0    0.0                0.0                  0.0  0.000   \n",
       "13  AC005027.3        0    0.0                0.0                  0.0  0.000   \n",
       "14  AC005592.2        0    0.0                0.0                  0.0  0.000   \n",
       "15  AC005609.2        0    0.0                0.0                  0.0  0.000   \n",
       "16  AC006369.2        0    0.0                0.0                  0.0  0.000   \n",
       "17  AC007381.2        0    0.0                0.0                  0.0  0.000   \n",
       "18  AC007563.5        3    0.0                0.0                  0.0  0.000   \n",
       "19  AC007796.1        0    0.0                0.0                  0.0  0.000   \n",
       "\n",
       "    SIFTpred  GERPrankscore  eigenraw  eigenpcraw  ...  qvalileum  qvalpancr  \\\n",
       "0        0.0            0.0       0.0         0.0  ...   0.148238   0.274318   \n",
       "1        0.0            0.0       0.0         0.0  ...   0.000056   0.006901   \n",
       "2        0.0            0.0       0.0         0.0  ...   0.156097   0.234632   \n",
       "3        0.0            0.0       0.0         0.0  ...   0.145449   0.003470   \n",
       "4        0.0            0.0       0.0         0.0  ...   0.262023   0.016786   \n",
       "5        0.0            0.0       0.0         0.0  ...   0.161608   0.103821   \n",
       "6        0.0            0.0       0.0         0.0  ...   0.332400   0.222817   \n",
       "7        0.0            0.0       0.0         0.0  ...   0.329621   0.306266   \n",
       "8        0.0            0.0       0.0         0.0  ...        NaN        NaN   \n",
       "9        0.0            0.0       0.0         0.0  ...        NaN        NaN   \n",
       "10       0.0            0.0       0.0         0.0  ...   0.200405        NaN   \n",
       "11       0.0            0.0       0.0         0.0  ...        NaN        NaN   \n",
       "12       0.0            0.0       0.0         0.0  ...        NaN        NaN   \n",
       "13       0.0            0.0       0.0         0.0  ...        NaN        NaN   \n",
       "14       0.0            0.0       0.0         0.0  ...        NaN        NaN   \n",
       "15       0.0            0.0       0.0         0.0  ...        NaN        NaN   \n",
       "16       0.0            0.0       0.0         0.0  ...   0.003511   0.060660   \n",
       "17       0.0            0.0       0.0         0.0  ...        NaN        NaN   \n",
       "18       0.0            0.0       0.0         0.0  ...        NaN        NaN   \n",
       "19       0.0            0.0       0.0         0.0  ...   0.363798        NaN   \n",
       "\n",
       "    qvalSaliv  qvalhippo  category  XGB prediction  Mostlikely    Likely  \\\n",
       "0    0.527257   0.278350   unknown               3    0.065207  0.342341   \n",
       "1    0.540455   0.124332   unknown               3    0.064875  0.110591   \n",
       "2    0.379621   0.000418   unknown               4    0.235413  0.232970   \n",
       "3    0.277516   0.153735   unknown               1    0.408808  0.213396   \n",
       "4    0.500810   0.333032   unknown               2    0.134594  0.586319   \n",
       "5    0.061630   0.235442   unknown               3    0.073422  0.212372   \n",
       "6    0.204093   0.131464   unknown               3    0.009654  0.132205   \n",
       "7    0.527257        NaN   unknown               2    0.023363  0.643415   \n",
       "8         NaN        NaN   unknown               2    0.030693  0.577755   \n",
       "9         NaN        NaN   unknown               2    0.031025  0.579909   \n",
       "10        NaN   0.193655   unknown               2    0.010058  0.743562   \n",
       "11        NaN        NaN   unknown               2    0.028106  0.640932   \n",
       "12        NaN        NaN   unknown               2    0.033931  0.563124   \n",
       "13        NaN        NaN   unknown               2    0.031055  0.583606   \n",
       "14   0.405341   0.216265   unknown               2    0.026258  0.624224   \n",
       "15        NaN        NaN   unknown               2    0.024364  0.678959   \n",
       "16        NaN        NaN   unknown               2    0.028955  0.510894   \n",
       "17        NaN        NaN   unknown               2    0.032494  0.660497   \n",
       "18        NaN        NaN   unknown               2    0.037280  0.494404   \n",
       "19        NaN   0.235333   unknown               2    0.041377  0.563376   \n",
       "\n",
       "    Possible  Leastlikely  \n",
       "0   0.561349     0.031103  \n",
       "1   0.643708     0.180826  \n",
       "2   0.118244     0.413373  \n",
       "3   0.338913     0.038883  \n",
       "4   0.185701     0.093387  \n",
       "5   0.678232     0.035974  \n",
       "6   0.847801     0.010340  \n",
       "7   0.327325     0.005896  \n",
       "8   0.378561     0.012992  \n",
       "9   0.375673     0.013392  \n",
       "10  0.240836     0.005544  \n",
       "11  0.318763     0.012198  \n",
       "12  0.389203     0.013742  \n",
       "13  0.372097     0.013242  \n",
       "14  0.336943     0.012575  \n",
       "15  0.286056     0.010621  \n",
       "16  0.399275     0.060876  \n",
       "17  0.295772     0.011237  \n",
       "18  0.456722     0.011594  \n",
       "19  0.378437     0.016810  \n",
       "\n",
       "[20 rows x 46 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator = dcv.GridSearchCV(XGB, xgb_parameters,  cv=inner_cv, iid=False, n_jobs=-1)\n",
    "\n",
    "estimator.fit(X, Y)\n",
    "\n",
    "prob1 = estimator.predict_proba(X2)[:,0]\n",
    "prob2 = estimator.predict_proba(X2)[:,1]\n",
    "prob3 = estimator.predict_proba(X2)[:,2]\n",
    "prob4 = estimator.predict_proba(X2)[:,3]\n",
    "\n",
    "predictions = list(estimator.predict(X2))\n",
    "#predictions = estimator.predict_proba(X2)\n",
    "\n",
    "output = pd.Series(data=predictions, index=dataset_unknown.index, name = 'XGB prediction')  \n",
    "output1 = pd.Series(data=prob1, index=dataset_unknown.index, name = 'Mostlikely') \n",
    "output2 = pd.Series(data=prob2, index=dataset_unknown.index, name = 'Likely') \n",
    "output3 = pd.Series(data=prob3, index=dataset_unknown.index, name = 'Possible') \n",
    "output4 = pd.Series(data=prob4, index=dataset_unknown.index, name = 'Leastlikely') \n",
    "df_total = pd.concat([dataset_unknown, output, output1, output2, output3, output4], axis=1)\n",
    "\n",
    "\n",
    "df_total.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total.to_csv('.\\XGB_predictions.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
