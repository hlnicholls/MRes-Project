{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Machine Learning for Predicting Blood Pressure Genes__ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy as numpy\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "np.random.seed(7) # for keras reproducibility, set before import as shown in keras examples. https://github.com/keras-team/keras/issues/2743\n",
    "from sklearn import datasets, metrics, preprocessing, model_selection\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelBinarizer,StandardScaler, LabelEncoder, OneHotEncoder \n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold, cross_val_score, cross_val_predict, GridSearchCV\n",
    "from sklearn.metrics import classification_report,confusion_matrix, mean_squared_error, matthews_corrcoef\n",
    "from sklearn.datasets import make_classification, load_digits\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LogisticRegression, LassoCV, LassoLarsCV, LassoLarsIC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "import dask_ml.model_selection as dcv\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "from keras import regularizers\n",
    "from keras.regularizers import l1\n",
    "reg = l1(0.001)\n",
    "\n",
    "\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "from itertools import cycle\n",
    "from scipy import interp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(303, 40)\n"
     ]
    }
   ],
   "source": [
    "dataset= pd.read_csv('BP_training.csv')\n",
    "data = dataset.drop([\"gene\"],1)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing\n",
    "### 1. Impute missing values by mean imputation for individual features\n",
    "\n",
    "### 2. Encode blood pressure gene categories from strings to floats: \n",
    "4 categories of affect on BP: certain, likely, possible, unlikely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3]\n"
     ]
    }
   ],
   "source": [
    "df = data.iloc[:,0:39]\n",
    "imputer = SimpleImputer(missing_values = np.nan, strategy = \"mean\")\n",
    "imputer = imputer.fit(df)\n",
    "df = imputer.transform(df)\n",
    "X = MinMaxScaler().fit_transform(df)\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "#convert the categorical columns into numeric\n",
    "encoded_value = le.fit_transform([\"certain\", \"likely\", \"possible\", \"unlikely\"])\n",
    "\n",
    "print(encoded_value)\n",
    "\n",
    "Y = le.fit_transform(data[\"category\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Models:\n",
    "\n",
    "### Hyper-parameter tuning with gridsearchCV, dask parallel processing for efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 7\n",
    "\n",
    "logreg = LogisticRegression(penalty='l1', solver='liblinear',multi_class='auto',random_state=seed)\n",
    "LR_par= {'penalty':['l1'], 'C': [0.5, 1, 5, 10], 'max_iter':[500, 1000, 5000]}\n",
    "\n",
    "rfc =RandomForestClassifier(n_estimators=100,random_state=seed)\n",
    "param_grid = {\"max_depth\": [5],\n",
    "             \"max_features\": [\"auto\", \"sqrt\"],\n",
    "              \"min_samples_split\": [50],\n",
    "              \"min_samples_leaf\": [50],\n",
    "              \"bootstrap\": [False, True],\n",
    "              \"criterion\": [\"entropy\",\"gini\"]}\n",
    "\n",
    "gbm = GradientBoostingClassifier(random_state=seed)\n",
    "param = {\"loss\":[\"deviance\"],\n",
    "    \"learning_rate\": [0.001, 0.01],\n",
    "    \"min_samples_split\": [50],\n",
    "    \"min_samples_leaf\": [50],\n",
    "    \"max_depth\":[5],\n",
    "    \"max_features\":[\"auto\"],\n",
    "    \"criterion\": [\"friedman_mse\"],\n",
    "    \"n_estimators\":[1000]\n",
    "    }\n",
    "\n",
    "\n",
    "XGB = XGBClassifier(num_class=4)\n",
    "xgb_parameters = {'nthread':[4], #when use hyperthread, xgboost may become slower\n",
    "              'objective':['multi:softprob'],\n",
    "              'learning_rate': [0.01, 0.001], #so called `eta` value\n",
    "              'max_depth': [5],\n",
    "              'min_child_weight': [11],\n",
    "              'silent': [1],\n",
    "              'subsample': [1.0],\n",
    "              'colsample_bytree': [0.6],\n",
    "              'n_estimators': [1000],\n",
    "              'missing':[-999],\n",
    "              'seed': [7]}\n",
    "                   \n",
    "\n",
    "mlp = MLPClassifier(random_state=seed)\n",
    "parameter_space = {'hidden_layer_sizes': [(50,)],\n",
    "     'activation': ['relu'],\n",
    "     'solver': ['adam'],\n",
    "     'max_iter': [10000],\n",
    "     'alpha': [0.001, 0.01],\n",
    "     'learning_rate': ['constant']}\n",
    "\n",
    "svm = SVC(gamma=\"scale\", probability=True,random_state=seed)\n",
    "tuned_parameters = {'kernel':('linear', 'rbf'), 'C':(0.1, 0.25, 0.5, 0.75, 1.0)}\n",
    "\n",
    "\n",
    "\n",
    "def baseline_model(learn_rate=0.01):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(100, input_dim=X.shape[1], activation='relu', activity_regularizer=l1(0.0001)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(75, activation='relu',activity_regularizer=l1(0.0001))) \n",
    "    model.add(Dense(50, activation='relu',activity_regularizer=l1(0.0001))) \n",
    "    model.add(Dense(25, activation='relu',activity_regularizer=l1(0.0001))) \n",
    "    model.add(Dense(4, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='Nadam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "keras = KerasClassifier(build_fn=baseline_model,batch_size=32, epochs=100, verbose=0)\n",
    "\n",
    "learn_rate = [0.001, 0.01]\n",
    "kerasparams = dict(learn_rate=learn_rate)\n",
    "\n",
    "\n",
    "inner_cv = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "outer_cv = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "\n",
    "models = []\n",
    "models.append(('LR', dcv.GridSearchCV(logreg, LR_par, cv=inner_cv, iid=False, n_jobs=-1)))\n",
    "models.append(('SVM', dcv.GridSearchCV(svm, tuned_parameters, cv=inner_cv, iid=False, n_jobs=-1)))\n",
    "models.append(('RF', dcv.GridSearchCV(rfc, param_grid, cv=inner_cv,iid=False, n_jobs=-1)))\n",
    "models.append(('GBM', dcv.GridSearchCV(gbm, param, cv=inner_cv,iid=False, n_jobs=-1)))\n",
    "models.append(('XGB',dcv.GridSearchCV(XGB, xgb_parameters,  cv=inner_cv, iid=False, n_jobs=-1)))\n",
    "models.append(('MLP', dcv.GridSearchCV(mlp, parameter_space, cv=inner_cv,iid=False, n_jobs=-1)))\n",
    "models.append(('Keras', GridSearchCV(estimator=keras, param_grid=kerasparams, cv=inner_cv,iid=False, n_jobs=-1)))\n",
    "\n",
    "results = []\n",
    "names = []\n",
    "scoring = 'accuracy'\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation:\n",
    "### Nested k-fold cross-validation (k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nested CV Accuracy LR: 67.021858 (+/- 6.719667 )\n",
      "Test set accuracy: 72.13 %\n",
      "Best Parameters: \n",
      "{'C': 0.5, 'max_iter': 500, 'penalty': 'l1'}\n",
      "\n",
      "Nested CV Accuracy SVM: 65.699454 (+/- 6.643326 )\n",
      "Test set accuracy: 67.21 %\n",
      "Best Parameters: \n",
      "{'C': 1.0, 'kernel': 'rbf'}\n",
      "\n",
      "Nested CV Accuracy RF: 65.071038 (+/- 8.548003 )\n",
      "Test set accuracy: 67.21 %\n",
      "Best Parameters: \n",
      "{'bootstrap': False, 'criterion': 'gini', 'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 50, 'min_samples_split': 50}\n",
      "\n",
      "Nested CV Accuracy GBM: 71.644809 (+/- 4.440186 )\n",
      "Test set accuracy: 67.21 %\n",
      "Best Parameters: \n",
      "{'criterion': 'friedman_mse', 'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 50, 'min_samples_split': 50, 'n_estimators': 1000}\n",
      "\n",
      "Nested CV Accuracy XGB: 71.650273 (+/- 5.977817 )\n",
      "Test set accuracy: 72.13 %\n",
      "Best Parameters: \n",
      "{'colsample_bytree': 0.6, 'learning_rate': 0.001, 'max_depth': 5, 'min_child_weight': 11, 'missing': -999, 'n_estimators': 1000, 'nthread': 4, 'objective': 'multi:softprob', 'seed': 7, 'silent': 1, 'subsample': 1.0}\n",
      "\n",
      "Nested CV Accuracy MLP: 64.366120 (+/- 5.858382 )\n",
      "Test set accuracy: 54.10 %\n",
      "Best Parameters: \n",
      "{'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (50,), 'learning_rate': 'constant', 'max_iter': 10000, 'solver': 'adam'}\n",
      "\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nested CV Accuracy Keras: 65.688525 (+/- 8.051100 )\n",
      "Test set accuracy: 59.02 %\n",
      "Best Parameters: \n",
      "{'learn_rate': 0.01}\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.57377049, 0.72131148, 0.63934426, 0.76666667, 0.65      ]), array([0.6557377 , 0.60655738, 0.63934426, 0.78333333, 0.6       ]), array([0.52459016, 0.60655738, 0.6557377 , 0.78333333, 0.68333333]), array([0.67213115, 0.70491803, 0.68852459, 0.8       , 0.71666667]), array([0.6557377 , 0.73770492, 0.6557377 , 0.81666667, 0.71666667]), array([0.59016393, 0.73770492, 0.57377049, 0.66666667, 0.65      ]), array([0.62295082, 0.75409836, 0.55737705, 0.75      , 0.6       ])]\n"
     ]
    }
   ],
   "source": [
    "for name, model in models:\n",
    "    nested_cv_results = model_selection.cross_val_score(model, X, Y, cv=outer_cv, scoring=scoring)\n",
    "    results.append(nested_cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"Nested CV Accuracy %s: %f (+/- %f )\" % (name, nested_cv_results.mean()*100, nested_cv_results.std()*100)\n",
    "    print(msg)\n",
    "    model.fit(X_train, Y_train)\n",
    "    print('Test set accuracy: {:.2f}'.format(model.score(X_test, Y_test)*100),  '%')\n",
    "    print(\"Best Parameters: \\n{}\\n\".format(model.best_params_))\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Nested Cross-Validation Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Certain       0.00      0.00      0.00         4\n",
      "      Likely       0.59      0.84      0.70        19\n",
      "    Possible       0.50      0.31      0.38        13\n",
      "    Unlikely       0.92      0.96      0.94        25\n",
      "\n",
      "    accuracy                           0.72        61\n",
      "   macro avg       0.50      0.53      0.50        61\n",
      "weighted avg       0.67      0.72      0.68        61\n",
      "\n",
      "LR MCC: 0.5913104673680332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Certain       0.00      0.00      0.00         4\n",
      "      Likely       0.58      0.74      0.65        19\n",
      "    Possible       0.31      0.31      0.31        13\n",
      "    Unlikely       0.96      0.92      0.94        25\n",
      "\n",
      "    accuracy                           0.67        61\n",
      "   macro avg       0.46      0.49      0.47        61\n",
      "weighted avg       0.64      0.67      0.65        61\n",
      "\n",
      "SVM MCC: 0.5157924292439348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Certain       0.00      0.00      0.00         4\n",
      "      Likely       0.51      0.95      0.67        19\n",
      "    Possible       0.00      0.00      0.00        13\n",
      "    Unlikely       0.88      0.92      0.90        25\n",
      "\n",
      "    accuracy                           0.67        61\n",
      "   macro avg       0.35      0.47      0.39        61\n",
      "weighted avg       0.52      0.67      0.58        61\n",
      "\n",
      "RF MCC: 0.5505273568223312\n",
      "GBM report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Certain       0.00      0.00      0.00         4\n",
      "      Likely       0.59      0.68      0.63        19\n",
      "    Possible       0.36      0.38      0.37        13\n",
      "    Unlikely       0.96      0.92      0.94        25\n",
      "\n",
      "    accuracy                           0.67        61\n",
      "   macro avg       0.48      0.50      0.49        61\n",
      "weighted avg       0.65      0.67      0.66        61\n",
      "\n",
      "GBM MCC: 0.5174275326956864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Certain       0.00      0.00      0.00         4\n",
      "      Likely       0.67      0.74      0.70        19\n",
      "    Possible       0.46      0.46      0.46        13\n",
      "    Unlikely       0.89      0.96      0.92        25\n",
      "\n",
      "    accuracy                           0.72        61\n",
      "   macro avg       0.50      0.54      0.52        61\n",
      "weighted avg       0.67      0.72      0.69        61\n",
      "\n",
      "XGB MCC: 0.5846864267950294\n",
      "MLP report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Certain       0.00      0.00      0.00         4\n",
      "      Likely       0.47      0.47      0.47        19\n",
      "    Possible       0.16      0.23      0.19        13\n",
      "    Unlikely       0.95      0.84      0.89        25\n",
      "\n",
      "    accuracy                           0.54        61\n",
      "   macro avg       0.40      0.39      0.39        61\n",
      "weighted avg       0.57      0.54      0.55        61\n",
      "\n",
      "MLP MCC: 0.3361064394597724\n",
      "Keras report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Certain       0.00      0.00      0.00         4\n",
      "      Likely       0.55      0.58      0.56        19\n",
      "    Possible       0.33      0.46      0.39        13\n",
      "    Unlikely       0.96      0.88      0.92        25\n",
      "\n",
      "    accuracy                           0.64        61\n",
      "   macro avg       0.46      0.48      0.47        61\n",
      "weighted avg       0.63      0.64      0.63        61\n",
      "\n",
      "Keras MCC: 0.47435588561001113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "for name, model in models:\n",
    "    model.fit(X_train, Y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    target_names=['Certain', 'Likely', 'Possible', 'Unlikely']\n",
    "    print(name, 'report:','\\n', classification_report(Y_test, y_pred, target_names=target_names))\n",
    "    print(name, 'MCC:', matthews_corrcoef(Y_test, y_pred)) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing models overfitting with randomised data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 41)\n",
      "Random data counts of label '0': 157\n",
      "Random data counts of label '1': 146\n",
      "Random data counts of label '2': 149\n",
      "Random data counts of label '3': 148\n",
      "(600, 39)\n",
      "(600,)\n"
     ]
    }
   ],
   "source": [
    "arr = np.arange(24000).reshape((600, 40))\n",
    "random = np.random.permutation(arr)\n",
    "ran = np.random.randint(4, size=600)\n",
    "rand = np.column_stack((random, ran))\n",
    "print(rand.shape)\n",
    "X1 = rand[0:600,0:39]\n",
    "Y1 = rand[0:600,-1]\n",
    "print(\"Random data counts of label '0': {}\".format(sum(ran==0)))\n",
    "print(\"Random data counts of label '1': {}\".format(sum(ran==1)))\n",
    "print(\"Random data counts of label '2': {}\".format(sum(ran==2)))\n",
    "print(\"Random data counts of label '3': {}\".format(sum(ran==3)))\n",
    "print(X1.shape)\n",
    "print(Y1.shape)\n",
    "X1 = MinMaxScaler().fit_transform(X1)\n",
    "\n",
    "X_train1, X_test1, Y_train1, Y_test1 = train_test_split(X1, Y1, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nested CV Accuracy LR: 23.958333 (+/- 4.516559 )\n",
      "Test Accuracy: 21.67 %\n",
      "Best Parameters: \n",
      "{'C': 5, 'max_iter': 500, 'penalty': 'l1'}\n",
      "\n",
      "Nested CV Accuracy SVM: 23.750000 (+/- 5.245699 )\n",
      "Test Accuracy: 24.17 %\n",
      "Best Parameters: \n",
      "{'C': 0.1, 'kernel': 'linear'}\n",
      "\n",
      "Nested CV Accuracy RF: 25.625000 (+/- 3.461093 )\n",
      "Test Accuracy: 30.00 %\n",
      "Best Parameters: \n",
      "{'bootstrap': False, 'criterion': 'entropy', 'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 50, 'min_samples_split': 50}\n",
      "\n",
      "Nested CV Accuracy GBM: 25.416667 (+/- 5.043216 )\n",
      "Test Accuracy: 25.00 %\n",
      "Best Parameters: \n",
      "{'criterion': 'friedman_mse', 'learning_rate': 0.001, 'loss': 'deviance', 'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 50, 'min_samples_split': 50, 'n_estimators': 1000}\n",
      "\n",
      "Nested CV Accuracy XGB: 25.625000 (+/- 5.496211 )\n",
      "Test Accuracy: 20.83 %\n",
      "Best Parameters: \n",
      "{'colsample_bytree': 0.6, 'learning_rate': 0.001, 'max_depth': 5, 'min_child_weight': 11, 'missing': -999, 'n_estimators': 1000, 'nthread': 4, 'objective': 'multi:softprob', 'seed': 7, 'silent': 1, 'subsample': 1.0}\n",
      "\n",
      "Nested CV Accuracy MLP: 23.125000 (+/- 2.825971 )\n",
      "Test Accuracy: 22.50 %\n",
      "Best Parameters: \n",
      "{'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (50,), 'learning_rate': 'constant', 'max_iter': 10000, 'solver': 'adam'}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nested CV Accuracy Keras: 20.833333 (+/- 4.218428 )\n",
      "Test Accuracy: 20.83 %\n",
      "Best Parameters: \n",
      "{'learn_rate': 0.001}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, model in models:\n",
    "    nested_cv_results = model_selection.cross_val_score(model, X_train1, Y_train1, cv=outer_cv, scoring=scoring)\n",
    "    results.append(nested_cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"Nested CV Accuracy %s: %f (+/- %f )\" % (name, nested_cv_results.mean()*100, nested_cv_results.std()*100)\n",
    "    print(msg)\n",
    "    model.fit(X_train1, Y_train1)\n",
    "    print('Test Accuracy: {:.2f}'.format(model.score(X_test1, Y_test1)*100),  '%')\n",
    "    print(\"Best Parameters: \\n{}\\n\".format(model.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importance\n",
    "\n",
    "- Without gridsearch due to it not working with coef and importance scikit functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All LR feature weights:\n",
      "[[ 0.55564656  0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.28532114  0.7507532\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.21044541  0.         -0.85625196  0.          0.          0.\n",
      "   0.          0.          0.        ]\n",
      " [-0.12780575  0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.         -0.84554366  0.         -0.02135656\n",
      "   0.          0.         -0.88845931  0.         -0.19450433  0.\n",
      "   0.60029169  0.          0.          1.00209303  0.         -0.37941679\n",
      "   0.          0.11931302  1.29006958  0.          0.41244765  0.\n",
      "   1.13221483  0.94441816  0.31491981]\n",
      " [ 0.44402164  0.          0.          0.          0.          0.\n",
      "   0.          0.         -1.15599297  0.          0.          0.\n",
      "   0.          0.         -0.17863729  0.23610751  0.          0.\n",
      "   0.          0.60866712  1.2570806   0.03377502  0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.73444308  0.          0.          0.45369771  0.          0.\n",
      "   0.          0.          0.26649894]\n",
      " [-0.57805368  0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "  -0.41055904  0.          0.          0.          0.          0.\n",
      "  -0.54467055  0.          0.          0.          0.          0.\n",
      "  -2.0915242  -1.12508993 -1.28935665 -0.62041376  0.         -0.63233125\n",
      "  -2.43371971 -0.32458258 -2.95229018]]\n",
      "Certain coefficients:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Catalog</td>\n",
       "      <td>0.555647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CLNDN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>InterVarautomated</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Polyphen2_HVAR_pred</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>REVEL</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SIFTpred</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GERPrankscore</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>eigenraw</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>eigenpcraw</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CADDrankscore</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DANNrankscore</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>fathmmrankscore</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>fathmmpred</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>minP</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>deepseasignifscore</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Exomiser.score</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>wgencode</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>regulomedscore</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>qvalAT</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>qvalLV</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>qvalAD</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>qvalAO</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>qvalTIB</td>\n",
       "      <td>0.285321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>qvalBL</td>\n",
       "      <td>0.750753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>qvalCO</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>qvaladiSub</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>qvaladiVsc</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>qvallung</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>qvalthyroid</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>qvalSkeletal</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>qvalpituit</td>\n",
       "      <td>0.210445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>qvalspleen</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>qvalleg</td>\n",
       "      <td>-0.856252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>qvalEsoph</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>qvalstomach</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>qvalileum</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>qvalpancr</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>qvalSaliv</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>qvalhippo</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0         0\n",
       "0               Catalog  0.555647\n",
       "1                 CLNDN  0.000000\n",
       "2     InterVarautomated  0.000000\n",
       "3   Polyphen2_HVAR_pred  0.000000\n",
       "4                 REVEL  0.000000\n",
       "5              SIFTpred  0.000000\n",
       "6         GERPrankscore  0.000000\n",
       "7              eigenraw  0.000000\n",
       "8            eigenpcraw  0.000000\n",
       "9         CADDrankscore  0.000000\n",
       "10        DANNrankscore  0.000000\n",
       "11      fathmmrankscore  0.000000\n",
       "12           fathmmpred  0.000000\n",
       "13                 minP  0.000000\n",
       "14   deepseasignifscore  0.000000\n",
       "15       Exomiser.score  0.000000\n",
       "16             wgencode  0.000000\n",
       "17       regulomedscore  0.000000\n",
       "18               qvalAT  0.000000\n",
       "19               qvalLV  0.000000\n",
       "20               qvalAD  0.000000\n",
       "21               qvalAO  0.000000\n",
       "22              qvalTIB  0.285321\n",
       "23               qvalBL  0.750753\n",
       "24               qvalCO  0.000000\n",
       "25           qvaladiSub  0.000000\n",
       "26           qvaladiVsc  0.000000\n",
       "27             qvallung  0.000000\n",
       "28          qvalthyroid  0.000000\n",
       "29         qvalSkeletal  0.000000\n",
       "30           qvalpituit  0.210445\n",
       "31           qvalspleen  0.000000\n",
       "32              qvalleg -0.856252\n",
       "33            qvalEsoph  0.000000\n",
       "34          qvalstomach  0.000000\n",
       "35            qvalileum  0.000000\n",
       "36            qvalpancr  0.000000\n",
       "37            qvalSaliv  0.000000\n",
       "38            qvalhippo  0.000000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression(penalty='l1', C=0.5, max_iter=500, solver='liblinear',multi_class='auto') \n",
    "logreg.fit(X_train, Y_train)\n",
    "print('All LR feature weights:')\n",
    "coef_certain=logreg.coef_[0]\n",
    "coef_likely=logreg.coef_[1]\n",
    "coef_possible_=logreg.coef_[2]\n",
    "coef_unlikely=logreg.coef_[3]\n",
    "coef=logreg.coef_\n",
    "intercept=logreg.intercept_\n",
    "classes=logreg.classes_\n",
    "print(coef)\n",
    "\n",
    "\n",
    "\n",
    "model_features =['Catalog','CLNDN', 'InterVarautomated', 'Polyphen2_HVAR_pred','REVEL', 'SIFTpred', 'GERPrankscore', 'eigenraw', 'eigenpcraw',\n",
    "                 'CADDrankscore','DANNrankscore','fathmmrankscore','fathmmpred','minP','deepseasignifscore','Exomiser.score','wgencode','regulomedscore',\n",
    "                 'qvalAT','qvalLV','qvalAD', 'qvalAO','qvalTIB','qvalBL','qvalCO','qvaladiSub','qvaladiVsc','qvallung','qvalthyroid','qvalSkeletal',\n",
    "                 'qvalpituit','qvalspleen', 'qvalleg', 'qvalEsoph', 'qvalstomach', 'qvalileum', 'qvalpancr', 'qvalSaliv', 'qvalhippo']\n",
    "\n",
    "feature = pd.DataFrame(np.array(model_features))\n",
    "\n",
    "output1 = list(coef_certain)\n",
    "\n",
    "df = pd.DataFrame(np.array(output1))\n",
    "\n",
    "df_total = pd.concat([feature, df], axis=1)\n",
    "print(\"Certain coefficients:\")\n",
    "df_total.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFC Feature ranking:\n",
      "1. feature 36 (0.186342)\n",
      "2. feature 38 (0.174243)\n",
      "3. feature 34 (0.167475)\n",
      "4. feature 32 (0.111695)\n",
      "5. feature 26 (0.092615)\n",
      "6. feature 33 (0.092156)\n",
      "7. feature 30 (0.088425)\n",
      "8. feature 14 (0.017001)\n",
      "9. feature 27 (0.012405)\n",
      "10. feature 28 (0.011994)\n",
      "11. feature 15 (0.011828)\n",
      "12. feature 22 (0.010982)\n",
      "13. feature 37 (0.006936)\n",
      "14. feature 29 (0.006354)\n",
      "15. feature 20 (0.005459)\n",
      "16. feature 16 (0.001806)\n",
      "17. feature 23 (0.001757)\n",
      "18. feature 35 (0.000527)\n",
      "19. feature 6 (0.000000)\n",
      "20. feature 8 (0.000000)\n",
      "21. feature 7 (0.000000)\n",
      "22. feature 3 (0.000000)\n",
      "23. feature 5 (0.000000)\n",
      "24. feature 4 (0.000000)\n",
      "25. feature 10 (0.000000)\n",
      "26. feature 2 (0.000000)\n",
      "27. feature 1 (0.000000)\n",
      "28. feature 9 (0.000000)\n",
      "29. feature 19 (0.000000)\n",
      "30. feature 11 (0.000000)\n",
      "31. feature 12 (0.000000)\n",
      "32. feature 13 (0.000000)\n",
      "33. feature 17 (0.000000)\n",
      "34. feature 18 (0.000000)\n",
      "35. feature 21 (0.000000)\n",
      "36. feature 24 (0.000000)\n",
      "37. feature 25 (0.000000)\n",
      "38. feature 31 (0.000000)\n",
      "39. feature 0 (0.000000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "rfc =RandomForestClassifier(bootstrap=False, criterion='gini', max_depth=10, max_features='auto', min_samples_leaf=50, min_samples_split=50)\n",
    "rfc.fit(X_train,Y_train)\n",
    "\n",
    "importances = rfc.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in rfc.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"RFC Feature ranking:\")\n",
    "\n",
    "for f in range(X_train.shape[1]):\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0 17 13 12 11 10  8  9  6  5  4  3  2  1  7 21 26 33 24 16 29 23 28 18\n",
      " 35 25 22 31 14 37 19 27 15 32 34 30 36 20 38]\n",
      " GBM Feature ranking:\n",
      "1. feature 38 (0.162630)\n",
      "2. feature 20 (0.143572)\n",
      "3. feature 36 (0.102540)\n",
      "4. feature 30 (0.102159)\n",
      "5. feature 34 (0.099151)\n",
      "6. feature 32 (0.076635)\n",
      "7. feature 15 (0.058044)\n",
      "8. feature 27 (0.044745)\n",
      "9. feature 19 (0.042648)\n",
      "10. feature 37 (0.034958)\n",
      "11. feature 14 (0.017364)\n",
      "12. feature 31 (0.016550)\n",
      "13. feature 22 (0.015421)\n",
      "14. feature 25 (0.013181)\n",
      "15. feature 35 (0.012849)\n",
      "16. feature 18 (0.010020)\n",
      "17. feature 28 (0.010007)\n",
      "18. feature 23 (0.008457)\n",
      "19. feature 29 (0.008049)\n",
      "20. feature 16 (0.006942)\n",
      "21. feature 24 (0.006855)\n",
      "22. feature 33 (0.004811)\n",
      "23. feature 26 (0.001302)\n",
      "24. feature 21 (0.001108)\n",
      "25. feature 7 (0.000000)\n",
      "26. feature 1 (0.000000)\n",
      "27. feature 2 (0.000000)\n",
      "28. feature 3 (0.000000)\n",
      "29. feature 4 (0.000000)\n",
      "30. feature 5 (0.000000)\n",
      "31. feature 6 (0.000000)\n",
      "32. feature 9 (0.000000)\n",
      "33. feature 8 (0.000000)\n",
      "34. feature 10 (0.000000)\n",
      "35. feature 11 (0.000000)\n",
      "36. feature 12 (0.000000)\n",
      "37. feature 13 (0.000000)\n",
      "38. feature 17 (0.000000)\n",
      "39. feature 0 (0.000000)\n"
     ]
    }
   ],
   "source": [
    "gbm = GradientBoostingClassifier(criterion='friedman_mse', learning_rate=0.01, loss='deviance', max_depth=10, max_features='auto', min_samples_leaf=50, min_samples_split=50, n_estimators=500)\n",
    "\n",
    "gbm.fit(X_train,Y_train)\n",
    "\n",
    "feature_importance = gbm.feature_importances_\n",
    "# make importances relative to max importance\n",
    "feature_importance = 100.0 * (feature_importance / feature_importance.max())\n",
    "sorted_idx = np.argsort(feature_importance)\n",
    "pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "\n",
    "print(np.argsort(feature_importance))\n",
    "\n",
    "importances = gbm.feature_importances_\n",
    "\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\" GBM Feature ranking:\")\n",
    "\n",
    "for f in range(X_train.shape[1]):\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 9  1  2  3  4  5  6  7  8 17 10 11 12 23 16 14 21 24 13  0 35 26 29 28\n",
      " 33 37 22 19 18 15 31 32 27 20 38 30 36 25 34]\n",
      "XGB Feature ranking:\n",
      "1. feature 34 (0.198263)\n",
      "2. feature 25 (0.129527)\n",
      "3. feature 36 (0.095241)\n",
      "4. feature 30 (0.064993)\n",
      "5. feature 38 (0.056683)\n",
      "6. feature 20 (0.055852)\n",
      "7. feature 27 (0.054265)\n",
      "8. feature 32 (0.043217)\n",
      "9. feature 31 (0.033644)\n",
      "10. feature 15 (0.030014)\n",
      "11. feature 18 (0.026235)\n",
      "12. feature 19 (0.023550)\n",
      "13. feature 22 (0.021667)\n",
      "14. feature 37 (0.020541)\n",
      "15. feature 33 (0.019170)\n",
      "16. feature 28 (0.018504)\n",
      "17. feature 29 (0.017354)\n",
      "18. feature 26 (0.015698)\n",
      "19. feature 35 (0.013432)\n",
      "20. feature 0 (0.011945)\n",
      "21. feature 13 (0.010915)\n",
      "22. feature 24 (0.010598)\n",
      "23. feature 21 (0.010157)\n",
      "24. feature 14 (0.009828)\n",
      "25. feature 16 (0.004905)\n",
      "26. feature 23 (0.003802)\n",
      "27. feature 12 (0.000000)\n",
      "28. feature 11 (0.000000)\n",
      "29. feature 10 (0.000000)\n",
      "30. feature 17 (0.000000)\n",
      "31. feature 8 (0.000000)\n",
      "32. feature 7 (0.000000)\n",
      "33. feature 6 (0.000000)\n",
      "34. feature 5 (0.000000)\n",
      "35. feature 4 (0.000000)\n",
      "36. feature 3 (0.000000)\n",
      "37. feature 2 (0.000000)\n",
      "38. feature 1 (0.000000)\n",
      "39. feature 9 (0.000000)\n"
     ]
    }
   ],
   "source": [
    "XGB = XGBClassifier(colsample_bytree=0.6, learning_rate=0.001, max_depth=5, min_child_weight=11, missing=-999, n_estimators=1000, nthread=4, objective='multi:softprob', seed=7, silent=1, subsample=1.0)\n",
    "\n",
    "XGB.fit(X_train,Y_train)\n",
    "\n",
    "feature_importance = XGB.feature_importances_\n",
    "# make importances relative to max importance\n",
    "feature_importance = 100.0 * (feature_importance / feature_importance.max())\n",
    "sorted_idx = np.argsort(feature_importance)\n",
    "pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "\n",
    "print(np.argsort(feature_importance))\n",
    "\n",
    "importances = XGB.feature_importances_\n",
    "\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"XGB Feature ranking:\")\n",
    "\n",
    "for f in range(X_train.shape[1]):\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
       "    <thead>\n",
       "    <tr style=\"border: none;\">\n",
       "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
       "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "    </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.1413\n",
       "                \n",
       "                    &plusmn; 0.0298\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x32\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 84.39%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0992\n",
       "                \n",
       "                    &plusmn; 0.0209\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x20\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 93.02%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0314\n",
       "                \n",
       "                    &plusmn; 0.0193\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x27\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 93.54%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0281\n",
       "                \n",
       "                    &plusmn; 0.0142\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x36\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 93.81%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0264\n",
       "                \n",
       "                    &plusmn; 0.0040\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x0\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 94.65%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0215\n",
       "                \n",
       "                    &plusmn; 0.0110\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x16\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 94.65%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0215\n",
       "                \n",
       "                    &plusmn; 0.0142\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x33\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 95.24%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0182\n",
       "                \n",
       "                    &plusmn; 0.0040\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x21\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 95.39%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0174\n",
       "                \n",
       "                    &plusmn; 0.0096\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x30\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 95.55%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0165\n",
       "                \n",
       "                    &plusmn; 0.0196\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x31\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 95.70%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0157\n",
       "                \n",
       "                    &plusmn; 0.0121\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x19\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 95.86%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0149\n",
       "                \n",
       "                    &plusmn; 0.0099\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x22\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.19%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0132\n",
       "                \n",
       "                    &plusmn; 0.0096\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x17\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.19%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0132\n",
       "                \n",
       "                    &plusmn; 0.0121\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x23\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.19%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0132\n",
       "                \n",
       "                    &plusmn; 0.0121\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x24\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.36%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0124\n",
       "                \n",
       "                    &plusmn; 0.0052\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x15\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.36%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0124\n",
       "                \n",
       "                    &plusmn; 0.0117\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x38\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.53%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0116\n",
       "                \n",
       "                    &plusmn; 0.0062\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x37\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.53%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0116\n",
       "                \n",
       "                    &plusmn; 0.0033\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x26\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.53%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0116\n",
       "                \n",
       "                    &plusmn; 0.0081\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x18\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "    \n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 96.53%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 19 more &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "    \n",
       "    </tbody>\n",
       "</table>\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model = KerasClassifier(build_fn=baseline_model, epochs=150, batch_size=32, verbose=0)\n",
    "my_model.fit(X_train, Y_train) \n",
    "\n",
    "perm = PermutationImportance(my_model, random_state=1).fit(X_train, Y_train)\n",
    "df = pd.DataFrame(X_train)\n",
    "eli5.show_weights(perm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
       "    <thead>\n",
       "    <tr style=\"border: none;\">\n",
       "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
       "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "    </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0421\n",
       "                \n",
       "                    &plusmn; 0.0160\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x20\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 82.25%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0355\n",
       "                \n",
       "                    &plusmn; 0.0170\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x27\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 86.86%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0231\n",
       "                \n",
       "                    &plusmn; 0.0112\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x30\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 87.19%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0223\n",
       "                \n",
       "                    &plusmn; 0.0206\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x19\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 89.25%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0174\n",
       "                \n",
       "                    &plusmn; 0.0184\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x38\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 90.35%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0149\n",
       "                \n",
       "                    &plusmn; 0.0153\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x21\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 90.35%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0149\n",
       "                \n",
       "                    &plusmn; 0.0066\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x16\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 90.73%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0140\n",
       "                \n",
       "                    &plusmn; 0.0243\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x36\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 91.12%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0132\n",
       "                \n",
       "                    &plusmn; 0.0062\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x15\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 91.91%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0116\n",
       "                \n",
       "                    &plusmn; 0.0205\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x33\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 92.32%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0107\n",
       "                \n",
       "                    &plusmn; 0.0066\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x24\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 93.17%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0091\n",
       "                \n",
       "                    &plusmn; 0.0132\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x34\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 93.17%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0091\n",
       "                \n",
       "                    &plusmn; 0.0033\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x18\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 93.17%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0091\n",
       "                \n",
       "                    &plusmn; 0.0062\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x0\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 93.61%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0083\n",
       "                \n",
       "                    &plusmn; 0.0209\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x37\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 94.06%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0074\n",
       "                \n",
       "                    &plusmn; 0.0062\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x17\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 95.02%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0058\n",
       "                \n",
       "                    &plusmn; 0.0040\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x6\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 95.02%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0058\n",
       "                \n",
       "                    &plusmn; 0.0040\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x35\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 95.53%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0050\n",
       "                \n",
       "                    &plusmn; 0.0132\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x31\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.06%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0041\n",
       "                \n",
       "                    &plusmn; 0.0117\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x28\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "    \n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 96.06%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 19 more &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "    \n",
       "    </tbody>\n",
       "</table>\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = SVC(gamma=\"scale\", probability=True,random_state=seed, C=0.75, kernel='rbf')\n",
    "\n",
    "svm.fit(X_train, Y_train) \n",
    "\n",
    "perm = PermutationImportance(svm, random_state=1).fit(X_train, Y_train)\n",
    "df = pd.DataFrame(X_train)\n",
    "eli5.show_weights(perm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
       "    <thead>\n",
       "    <tr style=\"border: none;\">\n",
       "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
       "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "    </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.1653\n",
       "                \n",
       "                    &plusmn; 0.0188\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x32\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 85.45%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.1050\n",
       "                \n",
       "                    &plusmn; 0.0457\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x20\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 85.69%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.1025\n",
       "                \n",
       "                    &plusmn; 0.0169\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x27\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 89.56%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0653\n",
       "                \n",
       "                    &plusmn; 0.0218\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x36\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 90.31%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0587\n",
       "                \n",
       "                    &plusmn; 0.0121\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x38\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 90.41%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0579\n",
       "                \n",
       "                    &plusmn; 0.0117\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x0\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 91.19%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0512\n",
       "                \n",
       "                    &plusmn; 0.0178\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x30\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 91.39%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0496\n",
       "                \n",
       "                    &plusmn; 0.0148\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x22\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 93.40%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0339\n",
       "                \n",
       "                    &plusmn; 0.0081\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x33\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 93.52%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0331\n",
       "                \n",
       "                    &plusmn; 0.0173\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x19\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 93.98%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0298\n",
       "                \n",
       "                    &plusmn; 0.0191\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x29\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 94.33%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0273\n",
       "                \n",
       "                    &plusmn; 0.0134\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x16\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 95.20%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0215\n",
       "                \n",
       "                    &plusmn; 0.0062\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x15\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 95.47%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0198\n",
       "                \n",
       "                    &plusmn; 0.0169\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x37\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.29%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0149\n",
       "                \n",
       "                    &plusmn; 0.0066\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x26\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.29%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0149\n",
       "                \n",
       "                    &plusmn; 0.0040\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x21\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.44%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0140\n",
       "                \n",
       "                    &plusmn; 0.0112\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x31\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.44%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0140\n",
       "                \n",
       "                    &plusmn; 0.0084\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x23\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.59%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0132\n",
       "                \n",
       "                    &plusmn; 0.0121\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x25\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.59%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0132\n",
       "                \n",
       "                    &plusmn; 0.0081\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x11\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "    \n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 96.59%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 19 more &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "    \n",
       "    </tbody>\n",
       "</table>\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPClassifier(random_state=seed, activation='relu', alpha=0.001, hidden_layer_sizes=(50,), learning_rate='constant', max_iter=10000, solver='adam')\n",
    "mlp.fit(X_train, Y_train)\n",
    "mlpcoef=mlp.coefs_[0]\n",
    "\n",
    "#print('All MLP feature weights:')\n",
    "#coef=logreg.coef_[0]\n",
    "#print(mlpcoef)\n",
    "\n",
    "#output2 = list(mlpcoef)\n",
    "#df = pd.DataFrame(np.array(output2))\n",
    "#df_total = pd.concat([feature, df], axis=1)\n",
    "#df_total.head(28)\n",
    "\n",
    "\n",
    "perm = PermutationImportance(mlp, random_state=1).fit(X_train, Y_train)\n",
    "df = pd.DataFrame(X_train)\n",
    "eli5.show_weights(perm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unknown gene prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1990, 40)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\utils\\deprecation.py:66: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "dataset_unknown= pd.read_csv('BP_unknown.csv')\n",
    "dataunknown = dataset_unknown.drop([\"gene\"],1)\n",
    "print(dataunknown.shape)\n",
    "\n",
    "df =dataunknown.iloc[:,0:39]\n",
    "imputer = SimpleImputer(missing_values = np.nan, strategy = \"mean\")\n",
    "imputer = imputer.fit(df)\n",
    "df = imputer.transform(df)\n",
    "#print(df)\n",
    "X2 = MinMaxScaler().fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model(learn_rate=0.01):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(100, input_dim=X.shape[1], activation='relu', activity_regularizer=l1(0.0001)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(75, activation='relu',activity_regularizer=l1(0.0001))) \n",
    "    model.add(Dense(50, activation='relu',activity_regularizer=l1(0.0001))) \n",
    "    model.add(Dense(25, activation='relu',activity_regularizer=l1(0.0001))) \n",
    "    model.add(Dense(4, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='Nadam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "keras = KerasClassifier(build_fn=baseline_model,batch_size=32, epochs=100, verbose=0)\n",
    "\n",
    "learn_rate = [0.001, 0.01]\n",
    "kerasparams = dict(learn_rate=learn_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = GridSearchCV(estimator=keras, param_grid=kerasparams, cv=inner_cv,iid=False, n_jobs=-1)\n",
    "\n",
    "estimator.fit(X, Y)\n",
    "\n",
    "prob1 = estimator.predict_proba(X2)[:,0]\n",
    "prob2 = estimator.predict_proba(X2)[:,1]\n",
    "prob3 = estimator.predict_proba(X2)[:,2]\n",
    "prob4 = estimator.predict_proba(X2)[:,3]\n",
    "\n",
    "predictions = list(estimator.predict(X2))\n",
    "#predictions = estimator.predict_proba(X2)\n",
    "\n",
    "output = pd.Series(data=predictions, index=dataset_unknown.index, name = 'Keras prediction')  \n",
    "output1 = pd.Series(data=prob1, index=dataset_unknown.index, name = 'Certain') \n",
    "output2 = pd.Series(data=prob2, index=dataset_unknown.index, name = 'Likely') \n",
    "output3 = pd.Series(data=prob3, index=dataset_unknown.index, name = 'Possible') \n",
    "output4 = pd.Series(data=prob4, index=dataset_unknown.index, name = 'Unlikely') \n",
    "df_total = pd.concat([dataset_unknown, output, output1, output2, output3, output4], axis=1)\n",
    "\n",
    "\n",
    "df_total.head(10)\n",
    "df_total.to_csv('.\\Keras_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = dcv.GridSearchCV(XGB, xgb_parameters,  cv=inner_cv, iid=False, n_jobs=-1)\n",
    "\n",
    "estimator.fit(X, Y)\n",
    "\n",
    "prob1 = estimator.predict_proba(X2)[:,0]\n",
    "prob2 = estimator.predict_proba(X2)[:,1]\n",
    "prob3 = estimator.predict_proba(X2)[:,2]\n",
    "prob4 = estimator.predict_proba(X2)[:,3]\n",
    "\n",
    "predictions = list(estimator.predict(X2))\n",
    "#predictions = estimator.predict_proba(X2)\n",
    "\n",
    "output = pd.Series(data=predictions, index=dataset_unknown.index, name = 'XGB prediction')  \n",
    "output1 = pd.Series(data=prob1, index=dataset_unknown.index, name = 'Certain') \n",
    "output2 = pd.Series(data=prob2, index=dataset_unknown.index, name = 'Likely') \n",
    "output3 = pd.Series(data=prob3, index=dataset_unknown.index, name = 'Possible') \n",
    "output4 = pd.Series(data=prob4, index=dataset_unknown.index, name = 'Unlikely') \n",
    "df_total = pd.concat([dataset_unknown, output, output1, output2, output3, output4], axis=1)\n",
    "\n",
    "\n",
    "df_total.head(10)\n",
    "\n",
    "df_total.to_csv('.\\XGB_predictionsnew.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = dcv.GridSearchCV(gbm, param,  cv=inner_cv, iid=False, n_jobs=-1)\n",
    "\n",
    "estimator.fit(X, Y)\n",
    "\n",
    "prob1 = estimator.predict_proba(X2)[:,0]\n",
    "prob2 = estimator.predict_proba(X2)[:,1]\n",
    "prob3 = estimator.predict_proba(X2)[:,2]\n",
    "prob4 = estimator.predict_proba(X2)[:,3]\n",
    "\n",
    "predictions = list(estimator.predict(X2))\n",
    "#predictions = estimator.predict_proba(X2)\n",
    "\n",
    "output = pd.Series(data=predictions, index=dataset_unknown.index, name = 'GBM prediction')  \n",
    "output1 = pd.Series(data=prob1, index=dataset_unknown.index, name = 'Certain') \n",
    "output2 = pd.Series(data=prob2, index=dataset_unknown.index, name = 'Likely') \n",
    "output3 = pd.Series(data=prob3, index=dataset_unknown.index, name = 'Possible') \n",
    "output4 = pd.Series(data=prob4, index=dataset_unknown.index, name = 'Unlikely') \n",
    "df_total = pd.concat([dataset_unknown, output, output1, output2, output3, output4], axis=1)\n",
    "\n",
    "\n",
    "df_total.head(10)\n",
    "\n",
    "df_total.to_csv('.\\GBM_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
